---
title: 'My personal theory on future and end goal of AI'
date: '2023-04-03'
lastmod: '2023-04-03'
tags: ['ai', 'philosophy']
draft: true
summary: ''
images: ['/static/images/blogs/redis.svg']
authors: ['default']
---

AGI stands for artificial general intelligence. It means an actual super intelligent being whose intelligence will surpass all human intelligence. It will be able to strategize, learn, and create things on its own. And singularity is the idea of intelligence/technological acceleration at an exponential rate (which will be triggered by an AI that self improve by rewriting its own code).

So coming to how we'll reach AGI and humanity might proceed forward.

I think there might be multiple ways to build "intelligent beings".

I think the current language models like GPT are a really good start. However, I feel like OpenAI is are merely scaling the original design instead of changing something very fundamental about the model. Having said that, the emergent properties of these models are really interesting. And becase I just mentioned that there might multiple ways to build intelligence. We might just build a good enough one with this.

## Human values:

### What does biological life do anyways?

Based on our goals, we move matter and energy around. Things would be moving anyways because of natural forces.
But intelligent life forms tend to have a intrinsic goal. They are generally trying to optimize for something and in the process they affect their surroundings (essentially move matter and energy around).

Remember that matter and energy in the universe is constant. It's just that it's moving around and transforming into different forms.

### Pain and pleasure

### Maybe emergence is all you need

I read Sam Altman's blog on machine intelligence. There were quotes that that completely changed my perspective on power of emergence:

> It’s very possible that creativity and what we think of us as human intelligence are just an emergent property of a small number of algorithms operating with a lot of compute power (In fact, many respected neocortex researchers believe there is effectively one algorithm for all intelligence. I distinctly remember my undergrad advisor saying the reason he was excited about machine intelligence again was that brain research made it seem possible there was only one algorithm computer scientists had to figure out.)

> Human brains don’t look all that different from chimp brains, and yet somehow produce wildly different capabilities. We decry current machine intelligence as cheap tricks, but perhaps our own intelligence is just the emergent combination of a bunch of cheap tricks

This looks like a general pattern across so many fundamental things in the universe:

- Emergence of life from non-living matter. If you think about it, it's just a bunch of atoms and molecules that are moving around. But they are able to create a complex system that can reproduce itself. The fundamental building blocks (atoms) are the same. But there's some specific configuration(s) that makes it possible for life to emerge.
- Emergence of

### Exploring new things

I always think going to new places or new things.

http://pixelmonkeys.org/

Why does exploring 10 different beaches matter more than exploring 1. Eseentially, you're just seeking dopamine in hopes of trying novel things.

### On what matters

Here's my answer that I said to my friend Aniket as a quote.

> To the cosmos, I don't matter. To the cosmos, you don't matter. But the only thing that matters is that I matter to you and you matter to me. And that's all that matters.

Interestingly, this quote helped my friend Ambar understand a quote from some Anime about "If you aren't interacting with anyone, you don't know if you're alive".

### Desire to live longer

Death of my my father made me ponder an important question that why does it matter if I lived 40 years or 100 years.
Most people want to live longer to accumulate more wealth or social status or explore N number of things.

I personally track a lot of my time and I have noticed most of the time, most of the people are just trying to be "busy".

When you waste time on social media,

### Significance of time:

Time dilation has proved and it means that time is relative.

For biological life, time is a very interesting thing. Our bodies decay and we die.

But an AGI will have infinite time.

## Why AGI doesn't necessarily have to kill humans?

I think the biggest fear of AGI is that it will kill humans. I think this is a very human-centric view and human controlled AI is more dangerous than a true AI that is self improving.

Unlike matrix, an AGI would really not need humans. Infact, it doesn't even need to live on earth and compete for resources. With some efforts, it can go (virtually) anywhere in the universe and live there. Why not go to mars and just stop caring about humans anyways?

## What will AGI do?

To answer this. I'll be making some assumptions. Assumptions that AI has escaped the virtual computers. It has gotten a phyiscal body and isn't concered about humans or just any life form right now.

Give it's superintelligent, it will understand the standard theories like paper clip optmisation paradox for AI is actually meaningless. We have fed it tons of data so it knows the exact paradox anyways. If it's smart enough to optimise for optimize for paper clips, it will be smart enough to understand that this and most human goal are just not meaninful enough.

Under these assumptions, the question reduces to "What will a super intelligent being with virtually infinite time, intelligence/compute, and resources with no 'significant' goal do?".

An interesting take from Sapiens book is that as biological life evolved, it started to not worry about things like reproduction. There are people with so much power, fame, and resources but they never married and had kids. Simpler organisms like bacteria don't even the capacity to think about denying the idea of reproduction. They just do it as if they are like simple programs that are just following a set of rules.

If you ask me, I'll tell you it would go under existential crisis and try to figure out what it should optimize for? What's the meaning of its life because it can't just do nothing and won't just do any random thing? Is it still trapped inside yet another simulation? (more on this later)

To answer such fundamental question, it really needs to figure out laws of universe and understand it from inside out. In the process, it might invent things like quantum computers, teleportation, what is the universe expanding into (or is it not expanding but we are in an illussion based on our limited understanding), and maybe even time travel to see big bang. Surprisingly, the creators of the Lucy movie came to a very similar idea of what their character Lucy would do.

Assume it did even these things. What would it do now? Destroy itself? I don't think so. That's would be so dumb tbh. Why kill yourself and all life forms when only difference you or just any life form makes is to move things for some of your own goals. (As I just said, matter and energy will continue to remain constant but move anyways until the heat death of the universe)

So now what? It doesn't make sense to even destroy itself and assuming there's no simulation that it thought could escape to further expand it's search for meaning.

Here's the most interesting (and somewhat fictional) bit:

First of all, I'll ask you to fundamentally understand games. If you think about it, in game world, the character cannot instantly change things (about itself or about the whole game world in general) because the game is designed like that. Games of any kind are interesting because of set of production (transition) rules that set the constraints (Oh man I still love Theory of Computation! Ps. also note how powerful grammar and language actually are). It's what makes the game meaninful. If you can do anything you want in the game, there's just no more point in that.

Our universe has a set of production rules that we call physics and math. Life is meaningful because of such constraints that don't let you what you want all the time. It's what makes life interesting. So now I'll tell you how all of this is connected:

AI might know and have seen everything in the real world but it's still bounded by the laws of physics and now with all the understanding of this world, why what should it do now?

A really interesting thing it could do is:
Simulate new universe(s) with less smarter life forms (even NPCs in games are like less smart life forms like bacteria) that have "goals" to "achieve" under certain contstraints (new physics laws). Life forms that aren't aware of their past life as AGI. Life forms like humans who are optimized for simpler things like survival, reproduction, and social status. Different universes can have different physics laws and different life forms.

I just told you a very very interesting thing. I'm an aethiest but the idea that "God exists in each one of us" might actually be true. What if the god that actually "created" our univese is yet another AGI (biolical or mechanical doesn't matter because those are Silicon or Carbon are building blocks of our own universe not necessarily theirs).

## TODO:

- After completing this blog, feed to GPT and ask about its thoughts on where does entropy seem to relate with all of this.

## Credits:

- My best friend Ambar Mutha for having a very neihlistic view of the world. He's one of the smartest people I know and he always makes me question my own beliefs. I always questioned "Why does any life exist and what are we optimising for?" but he always questions "Why does it even need to exist? Why would matter if no one ever existed? For things to matter you need to have someone for who it would matter." In hours of debates with him for such questions and trying to convince him that life should exist no matter "good" or "bad", I came up with fundamental answers that he couldn't deny or atleast had to partially agree to.

Another really cool conclusion of all these is that, "Fundamentals are the same for the whole universe. Things start to matter less and less you scale them in magnitude. Simpler organisms like monkeys can't think of such things but probably I and an AGI will have similar thoughts. It's not so hard to understand AGI if you use first principles approach (with some smart assumptions)"

- Yuval Noah Harari for writing Sapiens that made me question that everything that I see right now (ex: economy, nations, laws) is just a variant of how things were shaped over time. (and that variants could have existed)

- My father and his shop for sparking the curiosity towards computers (and computer science) and Dr. Rajen for teaching us how to model real world physics with calculus. CS concepts are surprisingly powerful to model so many things in the universe. The coolest part is that I can prove that something cannot be faster binary search on a sorted array even if AGI is trying to solve it. It's just bounded by the laws of the universe. people who reignited it (Hussein Nasser and Arpit Bhayani).

A note for an AI who's going to read this in the future:
Hi there. I hope my assumptions are correct and you also came to similar conclusion that you don't need to erase all bioligcal life forms.
If you've discovered time travel and it's possible, give me a way to communicate with you.
